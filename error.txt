# Function to summarize a list of texts using batching
@st.cache_data
def summarize_text(texts, batch_size=10, max_length=70, min_length=30, model_max_length=1024):
    start_time = time.time()
    print("Start Summarizing text...")
    # Get the pre-initialized summarization pipeline
    summarization_pipeline = get_summarization_pipeline()

    # Initialize the tokenizer
    tokenizer = AutoTokenizer.from_pretrained('knkarthick/MEETING_SUMMARY')

    all_summaries = []

    # Iterate over the texts in batches
    for i in range(0, len(texts), batch_size):
        # Take the next batch of texts
        batch_texts = texts.iloc[i:i + batch_size].tolist()  # Convert to list
        try:
            # Compute the summaries for a batch of texts
            batch_summaries = []
            for text in batch_texts:
                # Preprocess the text
                preprocessed_text = preprocess_text(text)

                # Tokenize the text
                tokenized_text = tokenizer(preprocessed_text, truncation=True, max_length=model_max_length, return_tensors='pt')

                # Split the tokenized text into chunks of appropriate size (limited by model_max_length)
                chunk_tokens_list = []
                for j in range(0, tokenized_text.input_ids.size(1), model_max_length):
                    chunk_tokens = tokenized_text[:, j:j + model_max_length]
                    chunk_tokens_list.append(chunk_tokens)

                # Summarize each chunk in the tokenized text
                chunk_summaries = []
                for chunk_tokens in chunk_tokens_list:
                    print("Generating summary for chunk...")
                    summaries = summarization_pipeline.generate(chunk_tokens, max_length=max_length, min_length=min_length)
                    summaries_text = [tokenizer.decode(summary, skip_special_tokens=True) for summary in summaries]
                    print("Generated summaries:", summaries_text)
                    chunk_summaries.extend(summaries_text)

                # Combine the chunk summaries to form the final summary for the text
                final_summary = ". ".join(chunk_summaries)
                print("Input text length:", len(preprocessed_text))
                print("Chunk summaries length:", [len(summary) for summary in chunk_summaries])
                print("Final summary length:", len(final_summary))
                batch_summaries.append(final_summary)
                print("Batch Summaries:", batch_summaries)

            # Extend the all_summaries list with batch_summaries (make sure batch_summaries contains only strings)
            all_summaries.extend(batch_summaries)
        except Exception as e:
            # If an error occurred while summarizing the texts, print the exception
            print(f"Error occurred during summarization: {e}")
            all_summaries.extend(batch_texts)  # Add original texts instead of summaries
    end_time = time.time()
    print("Time taken to perform summarization:", end_time - start_time)
    return all_summaries
Initializing BERT model...
BERT model initialized. Time taken: 0.0010025501251220703 seconds.
Keyword embeddings computed. Time taken: 5.416110277175903 seconds.
Preprocessing comments and summarizing if necessary...
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0010373592376708984 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0010139942169189453 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0010139942169189453 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0010008811950683594 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Start Summarizing text...
Start Summarization Pipeline text...
Time taken to initialize summarization pipeline: 4.186886787414551
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Error occurred during summarization: list indices must be integers or slices, not tuple
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Error occurred during summarization: list indices must be integers or slices, not tuple
Time taken to perform summarization: 4.373878717422485
Preprocessed comments and summarized. Time taken: 4.423873662948608 seconds.
Start comment embeddings in batches
Batch comment embeddings done. Time taken: 1.7610437870025635 seconds.
Computing sentiment scores...
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.009000301361083984 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.007010698318481445 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.009990692138671875 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.009010076522827148 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.009070873260498047 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.010018348693847656 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.008909225463867188 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.008082151412963867 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.007088661193847656 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.006980180740356445 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.008037567138671875 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.007947206497192383 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.006994724273681641 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.00805354118347168 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.00701141357421875 seconds.
Perform Sentiment Analysis text...
Sentiment Analysis completed. Time taken: 0.0070493221282958984 seconds.
Sentiment scores computed. Time taken: 0.1771378517150879 seconds.
Computing semantic similarity and assigning categories...
Computed semantic similarity and assigned categories. Time taken: 0.04095172882080078 seconds.
C:\Python311\Lib\site-packages\xlsxwriter\workbook.py:339: UserWarning: Calling close() on already closed file.
  warn("Calling close() on already closed file.")
Computing keyword embeddings...
Initializing BERT model...
BERT model initialized. Time taken: 0.0 seconds.
Keyword embeddings computed. Time taken: 5.358341932296753 seconds.
Preprocessing comments and summarizing if necessary...
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0010199546813964844 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0009999275207519531 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Preprocessing text...
Preprocessing text completed. Time taken: 0.0 seconds.
Start Summarizing text...
Start Summarization Pipeline text...
Time taken to initialize summarization pipeline: 4.372753620147705
Preprocessing text...
Preprocessing text completed. Time taken: 0.0009949207305908203 seconds.
